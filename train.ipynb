{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'contempt', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_path_1x = \"archive/data_relabeled_balanced_1x/train\"\n",
    "test_path_1x = \"archive/data_relabeled_balanced_1x/test\"\n",
    "train_path_2x = \"archive/data_relabeled_balanced_2x/train\"\n",
    "test_path_2x = \"archive/data_relabeled_balanced_2x/test\"\n",
    "train_path_3x = \"archive/data_relabeled_balanced_3x/train\"\n",
    "test_path_3x = \"archive/data_relabeled_balanced_3x/test\"\n",
    "\n",
    "train_class_1x = next(os.walk(train_path_1x))[1]\n",
    "test_class_1x = next(os.walk(test_path_1x))[1]\n",
    "train_class_2x = next(os.walk(train_path_2x))[1]\n",
    "test_class_2x = next(os.walk(test_path_2x))[1]\n",
    "train_class_3x = next(os.walk(train_path_3x))[1]\n",
    "test_class_3x = next(os.walk(test_path_3x))[1]\n",
    "\n",
    "print(\"train_path_1x：\",train_class_1x)\n",
    "print(\"test_path_1x\",test_class_1x)\n",
    "print(\"train_path_2x：\",train_class_2x)\n",
    "print(\"test_path_2x\",test_class_2x)\n",
    "print(\"train_path_3x：\",train_class_3x)\n",
    "print(\"test_path_3x\",test_class_3x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本: 2.6.0+cu124\n",
      "CUDA 可用: True\n",
      "CUDA 设备数量: 1\n",
      "当前设备: 0\n",
      "设备名称: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch 版本:\", torch.__version__)\n",
    "print(\"CUDA 可用:\", torch.cuda.is_available())\n",
    "print(\"CUDA 设备数量:\", torch.cuda.device_count())\n",
    "print(\"当前设备:\", torch.cuda.current_device())\n",
    "print(\"设备名称:\", torch.cuda.get_device_name(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:10809\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:10809\"\n",
    "os.environ[\"TORCH_HOME\"] = \".\"\n",
    "\n",
    "# 禁用torch ssl验证\n",
    "# os.environ[\"CURL_CA_BUNDLE\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\conda\\envs\\workspace\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully.\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:57<00:00,  1.38s/it, loss=1.883, acc=37.0%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch1_acc56.4.pth\n",
      "Learning rate: 2.0e-04\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:53<00:00,  1.37s/it, loss=2.172, acc=54.9%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch2_acc65.0.pth\n",
      "Learning rate: 2.0e-04\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:44<00:00,  1.35s/it, loss=1.814, acc=61.7%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch3_acc67.7.pth\n",
      "Learning rate: 2.0e-04\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:57<00:00,  1.38s/it, loss=1.366, acc=65.6%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch4_acc69.6.pth\n",
      "Learning rate: 2.0e-04\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:49<00:00,  1.36s/it, loss=1.351, acc=69.8%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch5_acc70.6.pth\n",
      "Learning rate: 2.0e-04\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [09:14<00:00,  1.42s/it, loss=1.332, acc=71.8%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch6_acc71.3.pth\n",
      "Learning rate: 2.0e-04\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.482, acc=76.3%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2.0e-04\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:53<00:00,  1.37s/it, loss=1.057, acc=78.7%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2.0e-04\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=2.270, acc=81.5%, lr=2.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch9_acc72.4.pth\n",
      "Learning rate: 1.0e-04\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.670, acc=82.3%, lr=1.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch10_acc72.8.pth\n",
      "Learning rate: 1.0e-04\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.040, acc=83.3%, lr=1.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-04\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.572, acc=82.7%, lr=1.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-04\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.626, acc=82.4%, lr=1.0e-04, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.594, acc=85.6%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch14_acc73.0.pth\n",
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.944, acc=85.5%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch15_acc73.0.pth\n",
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.034, acc=84.4%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch16_acc73.4.pth\n",
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.322, acc=86.1%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.882, acc=84.3%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.230, acc=85.6%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:50<00:00,  1.36s/it, loss=1.005, acc=86.1%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.126, acc=84.6%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch21_acc73.6.pth\n",
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.719, acc=84.2%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:53<00:00,  1.37s/it, loss=2.016, acc=84.6%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch23_acc73.7.pth\n",
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.630, acc=85.8%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:51<00:00,  1.37s/it, loss=1.162, acc=85.9%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.008, acc=86.5%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch26_acc73.9.pth\n",
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.659, acc=86.0%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.572, acc=84.6%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.967, acc=87.5%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-05\n",
      "\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.946, acc=86.8%, lr=5.0e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: visionModel\\best_model_epoch30_acc74.1.pth\n",
      "Learning rate: 2.5e-05\n",
      "\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.542, acc=85.5%, lr=2.5e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2.5e-05\n",
      "\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.348, acc=85.1%, lr=2.5e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2.5e-05\n",
      "\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:52<00:00,  1.37s/it, loss=1.560, acc=86.4%, lr=2.5e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.3e-05\n",
      "\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [08:50<00:00,  1.36s/it, loss=1.148, acc=86.4%, lr=1.3e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.3e-05\n",
      "\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████| 389/389 [28:00<00:00,  4.32s/it, loss=1.034, acc=88.0%, lr=1.3e-05, mem=1.2G]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.3e-05\n",
      "\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|██▋                 | 53/389 [06:20<40:10,  7.17s/it, loss=0.701, acc=88.1%, lr=1.3e-05, mem=1.2G]"
     ]
    }
   ],
   "source": [
    "# train_color.py\n",
    "\n",
    "# ----------------------\n",
    "# 1. 基础导入和环境配置\n",
    "# ----------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.amp import GradScaler,autocast\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# 设置代理和下载目录\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:10809\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:10809\"\n",
    "os.environ[\"TORCH_HOME\"] = \".\"\n",
    "from tqdm.auto import tqdm\n",
    "import psutil\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.functional\")\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------\n",
    "# 2. 基础配置\n",
    "# ----------------------\n",
    "# 2.1 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True  # 加速卷积运算\n",
    "if device.type == 'cuda':\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    print(\"Warning: GPU not available. Training on CPU.\")\n",
    "\n",
    "# 关键参数配置 (根据6GB显存优化)\n",
    "# 2.2 训练参数配置\n",
    "config = {\n",
    "    \"data_dir\": \"archive/data_relabeled_balanced_1x/train\",\n",
    "    \"batch_size\": 32,\n",
    "    \"grad_accum_steps\": 4,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_classes\": 8,\n",
    "    \"input_size\": 224,\n",
    "    \"valid_ratio\": 0.15,\n",
    "    \"seed\": 42,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"mixup_alpha\": 0.2,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"model_dir\": \"visionModel\",\n",
    "    \"freeze_blocks\": 2,\n",
    "    \"patience\": 15,        # 增加耐心值\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"T_0\": 10,            # 余弦退火周期\n",
    "    \"T_mult\": 2,          # 周期倍增因子\n",
    "}\n",
    "\n",
    "# 2.3 固定随机种子\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(config['seed'])\n",
    "\n",
    "# ----------------------\n",
    "# 内存优化数据集\n",
    "# 3. 数据集和数据加载\n",
    "# ----------------------\n",
    "# 3.1 数据集类定义\n",
    "class OptimizedDataset(Dataset):\n",
    "    \"\"\"优化的数据集类，支持内存缓存\"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) \n",
    "                             if os.path.isdir(os.path.join(root_dir, d)) and '_gray' not in d]) # 过滤掉灰度数据集\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 预加载图像路径\n",
    "        for cls in self.classes:\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            self.samples.extend([\n",
    "                (os.path.join(cls_dir, fname), self.class_to_idx[cls]) \n",
    "                for fname in os.listdir(cls_dir)\n",
    "                if fname.lower().endswith(('png', 'jpg', 'jpeg'))\n",
    "            ])\n",
    "        \n",
    "        # 内存优化：预加载小尺寸图像\n",
    "        self.cache = {}\n",
    "        if psutil.virtual_memory().available > 8*1024**3:  # 仅当内存>8GB时启用\n",
    "            for idx in tqdm(range(len(self.samples)), desc=\"预加载图像\"):\n",
    "                img_path, label = self.samples[idx]\n",
    "                self.cache[idx] = (Image.open(img_path).convert('RGB'), label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cache:\n",
    "            img, label = self.cache[idx]\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            # img = self.transform(img) # 转换为tensor\n",
    "            img = np.array(img)  # 转换为numpy array\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']\n",
    "            \n",
    "        return img, label\n",
    "\n",
    "# 3.2 数据增强定义\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(config['input_size'], config['input_size']),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    # 将ShiftScaleRotate替换为 Affine\n",
    "    A.Affine(\n",
    "        scale=(0.9, 1.1), # 允许图像随机缩放，范围为 0.9 到 1.1\n",
    "        translate_percent=(-0.1, 0.1),  # 允许图像随机平移，范围为 -10% 到 10%\n",
    "        rotate=(-15, 15), # 允许图像随机旋转，范围为 -15 到 15 度 \n",
    "        shear=(-10, 10),              # 加入轻微shear变换，范围设为 -10 到 10 度\n",
    "        interpolation=cv2.INTER_LINEAR, # 使用cv2.INTER_LINEAR进行线性插值\n",
    "        border_mode=cv2.BORDER_REFLECT_101, # 使用cv2.BORDER_REFLECT_101方式填充边缘\n",
    "        p=0.5 # 应用概率为 0.5\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    # A.CoarseDropout(max_holes=3, max_height=20, max_width=20, p=0.3),\n",
    "    # 修改 CoarseDropout 参数\n",
    "    A.CoarseDropout(\n",
    "        num_holes_range=(3, 6),           # 每次随机遮挡 3-6 个区域\n",
    "        hole_height_range=(0.1, 0.2),     # 高度为图像高度的 10%-20%\n",
    "        hole_width_range=(0.1, 0.2),      # 宽度为图像宽度的 10%-20%\n",
    "        fill=0,                     # 使用黑色填充\n",
    "        p=0.3                             # 应用概率为 0.3\n",
    "    ),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(config['input_size'], config['input_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# 3.3 创建数据加载器\n",
    "def create_data_loaders():\n",
    "    \"\"\"创建训练和验证数据加载器\"\"\"\n",
    "    # 创建数据集\n",
    "    full_dataset = OptimizedDataset(config['data_dir'], transform=train_transform)\n",
    "    train_size = int((1 - config['valid_ratio']) * len(full_dataset))\n",
    "    valid_size = len(full_dataset) - train_size\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(full_dataset, [train_size, valid_size])\n",
    "    valid_dataset.dataset.transform = valid_transform\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['num_workers'],\n",
    "        pin_memory=True,\n",
    "        # persistent_workers=True\n",
    "        persistent_workers=False # 关闭持续workers（多进程）\n",
    "    )\n",
    "    \n",
    "    # 验证数据加载器\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=config['batch_size']*2,\n",
    "        shuffle=False,\n",
    "        num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 返回训练和验证数据加载器\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "# ----------------------\n",
    "# 4. 模型相关\n",
    "# ----------------------\n",
    "# 4.1 模型创建函数\n",
    "def create_model():\n",
    "    \"\"\"创建并初始化模型（带重试机制）\"\"\"\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # 使用EfficientNet B0并加载ImageNet预训练权重\n",
    "            model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "            in_features = model.classifier[1].in_features\n",
    "            # 使用新的 classifier，加入 dropout 层以降低过拟合\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.Linear(in_features, config['num_classes'])\n",
    "            )\n",
    "            \n",
    "            # 冻结前 freeze_blocks 个阶段的参数以减少模型复杂度\n",
    "            for param in model.features[:config['freeze_blocks']].parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # 显存优化配置\n",
    "            model = model.to(device, memory_format=torch.channels_last)\n",
    "            print(\"Model created successfully.\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries} failed: {str(e)}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n",
    "\n",
    "# ----------------------\n",
    "# 5. 训练工具函数\n",
    "# ----------------------\n",
    "def print_memory_usage():\n",
    "    \"\"\"打印显存使用情况\"\"\"\n",
    "    if device.type == 'cuda':\n",
    "        mem = torch.cuda.memory_reserved(device) / 1e9\n",
    "        print(f\"当前显存占用: {mem:.2f}GB\")\n",
    "    else:\n",
    "        print(\"Training on CPU, no GPU memory usage available.\")\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    \"\"\"Mixup数据增强\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# ----------------------\n",
    "# 6. 训练和验证函数\n",
    "# ----------------------\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, scaler):\n",
    "    \"\"\"训练一个epoch\"\"\"\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, \n",
    "                       desc='Training',\n",
    "                       bar_format='{l_bar}{bar:20}{r_bar}{bar:-20b}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, (inputs, labels) in enumerate(progress_bar):\n",
    "        try:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Mixup数据增强\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, config['mixup_alpha'])\n",
    "            \n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                outputs = model(inputs)\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "                loss = loss / config['grad_accum_steps']  # 梯度累积\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (step + 1) % config['grad_accum_steps'] == 0 or (step + 1) == len(train_loader):\n",
    "                # 梯度裁剪\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), config['max_grad_norm'])\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (lam * predicted.eq(targets_a).sum().item() + \n",
    "                       (1 - lam) * predicted.eq(targets_b).sum().item())\n",
    "            total += labels.size(0)\n",
    "            train_acc = 100. * correct / total\n",
    "            \n",
    "            # 计算显存使用情况\n",
    "            mem_str = f\"{torch.cuda.memory_reserved(device)/1e9:.1f}G\" if device.type == 'cuda' else \"N/A\"\n",
    "            \n",
    "            # 更新进度条\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item()*config['grad_accum_steps']:.3f}\",\n",
    "                'acc': f\"{train_acc:.1f}%\",\n",
    "                'lr': f\"{optimizer.param_groups[0]['lr']:.1e}\",\n",
    "                'mem': mem_str\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error in training step: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return loss.item(), train_acc\n",
    "\n",
    "def validate(model, valid_loader, criterion):\n",
    "    \"\"\"验证模型并收集详细指标\"\"\"\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 收集预测结果和真实标签\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    class_correct = [0] * config['num_classes']\n",
    "    class_total = [0] * config['num_classes']\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad(), autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "            for inputs, labels in tqdm(valid_loader, desc='Validating', leave=False):\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                \n",
    "                # 收集预测结果\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # 计算每个类别的准确率\n",
    "                for label, pred in zip(labels, predicted):\n",
    "                    if label == pred:\n",
    "                        class_correct[label] += 1\n",
    "                    class_total[label] += 1\n",
    "                \n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        # 计算每个类别的准确率\n",
    "        class_accuracies = [100 * correct / total if total > 0 else 0 \n",
    "                           for correct, total in zip(class_correct, class_total)]\n",
    "        \n",
    "        return (valid_loss / len(valid_loader), 100. * correct / total, \n",
    "                all_preds, all_labels, class_accuracies)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in validation: {str(e)}\")\n",
    "        return float('inf'), 0.0, [], [], [0] * config['num_classes']\n",
    "\n",
    "# ----------------------\n",
    "# 7. 主训练循环\n",
    "# ----------------------\n",
    "def main():\n",
    "    \"\"\"主训练函数\"\"\"\n",
    "    os.makedirs(config['model_dir'], exist_ok=True)\n",
    "    \n",
    "    # 创建训练结果保存目录\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_dir = os.path.join(config['model_dir'], f'training_results_{timestamp}')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    train_loader, valid_loader = create_data_loaders()\n",
    "    model = create_model()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # 使用标签平滑的交叉熵损失\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=config['T_0'],\n",
    "        T_mult=config['T_mult'],\n",
    "        eta_min=config['min_lr']\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=config['patience'])\n",
    "    best_acc = 0.0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], \n",
    "        'valid_loss': [], 'valid_acc': [],\n",
    "        'learning_rates': [], 'class_accuracies': [],\n",
    "        'final_confusion_matrix': None\n",
    "    }\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n",
    "        \n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "        valid_loss, valid_acc, all_preds, all_labels, class_accuracies = validate(\n",
    "            model, valid_loader, criterion)\n",
    "        \n",
    "        # 记录历史\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['valid_loss'].append(valid_loss)\n",
    "        history['valid_acc'].append(valid_acc)\n",
    "        history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "        history['class_accuracies'].append(class_accuracies)\n",
    "        \n",
    "        # 在最后一个epoch或提前停止时保存混淆矩阵\n",
    "        if epoch == config['num_epochs']-1 or early_stopping.counter >= config['patience']:\n",
    "            conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "            history['final_confusion_matrix'] = conf_matrix\n",
    "            \n",
    "            # 打印分类报告\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(all_labels, all_preds))\n",
    "        \n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            save_path = os.path.join(\n",
    "                save_dir, \n",
    "                f'best_model_epoch{epoch+1}_acc{valid_acc:.1f}.pth'\n",
    "            )\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_acc': best_acc,\n",
    "                'history': history,\n",
    "            }, save_path)\n",
    "            print(f\"Saved best model to: {save_path}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Learning rate: {current_lr:.1e}\")\n",
    "        \n",
    "        # 每5个epoch绘制一次训练图\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            plot_training_history(history, save_dir)\n",
    "        \n",
    "        early_stopping(valid_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # 训练结束后绘制最终图表\n",
    "    plot_training_history(history, save_dir)\n",
    "    \n",
    "    # 保存完整训练历史\n",
    "    history_path = os.path.join(save_dir, 'training_history.pth')\n",
    "    torch.save(history, history_path)\n",
    "    print(f\"Saved training history to: {history_path}\")\n",
    "\n",
    "# ----------------------\n",
    "# 8. 可视化函数\n",
    "# ----------------------\n",
    "def plot_training_history(history, save_dir):\n",
    "    \"\"\"绘制详细的训练历史\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. 损失和准确率图\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['valid_loss'], label='Valid')\n",
    "    plt.title('Training/Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train')\n",
    "    plt.plot(history['valid_acc'], label='Valid')\n",
    "    plt.title('Training/Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 2. 学习率变化图\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['learning_rates'])\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # 3. 每个类别的准确率变化\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for i, class_acc in enumerate(zip(*history['class_accuracies'])):\n",
    "        plt.plot(class_acc, label=f'Class {i}')\n",
    "    plt.title('Per-Class Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'training_metrics_{timestamp}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. 混淆矩阵\n",
    "    if history['final_confusion_matrix'] is not None:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(history['final_confusion_matrix'], \n",
    "                   annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(os.path.join(save_dir, f'confusion_matrix_{timestamp}.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# 9. 程序入口\n",
    "# ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aweasd\\AppData\\Local\\Temp\\ipykernel_6484\\1619224066.py:120: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
      "C:\\Users\\aweasd\\AppData\\Local\\Temp\\ipykernel_6484\\1619224066.py:121: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n",
      "Selected best model: visionModel\\best_model_epoch30_acc74.1.pth (acc=74.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "预加载图像: 100%|██████████| 29217/29217 [00:24<00:00, 1206.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# train_gray.py\n",
    "\n",
    "# ----------------------\n",
    "# 1. 基础导入和配置\n",
    "# ----------------------\n",
    "import os\n",
    "# 设置代理和下载目录\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:10809\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:10809\"\n",
    "os.environ[\"TORCH_HOME\"] = \".\"\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import tqdm\n",
    "from train_color import (\n",
    "    device, seed_everything, OptimizedDataset,\n",
    "    GradScaler, autocast, A, ToTensorV2, tqdm, validate\n",
    ")\n",
    "import gc\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 2. 增强配置参数\n",
    "# ----------------------\n",
    "class GrayConfig:\n",
    "    # 自动查找最佳模型\n",
    "    @staticmethod\n",
    "    def find_best_model(model_dir=\"visionModel\"):\n",
    "        model_files = glob.glob(os.path.join(model_dir, \"best_model_epoch*.pth\"))\n",
    "        best_acc = -1\n",
    "        best_path = \"\"\n",
    "        \n",
    "        for file_path in model_files:\n",
    "            match = re.search(r\"acc([\\d.]+)\\.pth\", file_path)\n",
    "            if match:\n",
    "                acc = float(match.group(1))\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_path = file_path\n",
    "        \n",
    "        if not best_path:\n",
    "            raise FileNotFoundError(f\"No valid model found in {model_dir}\")\n",
    "        print(f\"Selected best model: {best_path} (acc={best_acc:.1f}%)\")\n",
    "        return best_path\n",
    "\n",
    "    # 训练参数\n",
    "    config = {\n",
    "        \"data_dir\": \"archive/data_relabeled_balanced_1x/train\",\n",
    "        \"model_dir\": \"visionModel_gray\",\n",
    "        \"pretrained\": find_best_model.__func__(),  # 自动选择最佳模型\n",
    "        \"batch_size\": 128,\n",
    "        \"grad_accum_steps\": 2,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"num_classes\": 8,\n",
    "        \"input_size\": 224,\n",
    "        \"valid_ratio\": 0.15,\n",
    "        \"num_workers\": 4 if os.cpu_count() > 4 else 0,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "        \"mixup_alpha\": 0.3,\n",
    "        \"label_smoothing\": 0.05,\n",
    "        \"freeze_stages\": 3,\n",
    "        \"unfreeze_layers\": [\"features.5\", \"features.6\", \"classifier\"],\n",
    "        \"lr_decay\": 0.95,\n",
    "        \"es_patience\": 5\n",
    "    }\n",
    "\n",
    "# ----------------------\n",
    "# 3. 数据集调整\n",
    "# ----------------------\n",
    "class GrayDataset(OptimizedDataset):\n",
    "    \"\"\"灰度专用数据集\"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.gray_classes = [d for d in os.listdir(root_dir) \n",
    "                            if d.endswith('_gray') and os.path.isdir(os.path.join(root_dir, d))]\n",
    "        super().__init__(root_dir, transform)\n",
    "        \n",
    "        # 重建class_to_idx映射\n",
    "        self.classes = [c.replace('_gray', '') for c in self.gray_classes]\n",
    "        self.class_to_idx = {cls:i for i, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # 重建样本列表\n",
    "        self.samples = []\n",
    "        for gray_cls in self.gray_classes:\n",
    "            cls_dir = os.path.join(root_dir, gray_cls)\n",
    "            label = self.class_to_idx[gray_cls.replace('_gray', '')]\n",
    "            self.samples.extend([\n",
    "                (os.path.join(cls_dir, fname), label)\n",
    "                for fname in os.listdir(cls_dir)\n",
    "                if fname.lower().endswith(('png', 'jpg', 'jpeg'))\n",
    "            ])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = super().__getitem__(idx)\n",
    "        return img, label\n",
    "\n",
    "# ----------------------\n",
    "# 4. 数据增强优化\n",
    "# ----------------------\n",
    "def get_gray_transforms():\n",
    "    \"\"\"灰度专用增强策略\"\"\"\n",
    "    return {\n",
    "        'train': A.Compose([\n",
    "            A.Resize(GrayConfig.config['input_size'], GrayConfig.config['input_size']),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Affine(\n",
    "                scale=(0.8, 1.2),\n",
    "                translate_percent=(-0.2, 0.2),\n",
    "                rotate=(-30, 30),\n",
    "                shear=(-15, 15),\n",
    "                p=0.7\n",
    "            ),\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(3, 7)),  # 模糊增强\n",
    "                A.MotionBlur(blur_limit=7),        # 运动模糊\n",
    "                A.GlassBlur(sigma=0.7, max_delta=2) # 玻璃模糊\n",
    "            ], p=0.3),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "            A.GaussNoise(\n",
    "                std=20.0,  # 标准差范围改为固定值\n",
    "                mean=0,    # 均值设为0\n",
    "                per_channel=True,  # 每个通道独立添加噪声\n",
    "                p=0.2\n",
    "            ),\n",
    "            A.CoarseDropout(\n",
    "                num_holes_range=(3, 6),           # 每次随机遮挡 3-6 个区域\n",
    "                hole_height_range=(0.1, 0.2),     # 高度为图像高度的 10%-20%\n",
    "                hole_width_range=(0.1, 0.2),      # 宽度为图像宽度的 10%-20%\n",
    "                fill=0,                     # 使用黑色填充\n",
    "                p=0.3                             # 应用概率为 0.3\n",
    "            ),\n",
    "            A.Normalize(mean=[0.5], std=[0.5]),  # 单通道标准化\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        'valid': A.Compose([\n",
    "            A.Resize(GrayConfig.config['input_size'], GrayConfig.config['input_size']),\n",
    "            A.Normalize(mean=[0.5], std=[0.5]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    }\n",
    "\n",
    "# ----------------------\n",
    "# 5. 模型适配优化\n",
    "# ----------------------\n",
    "class GrayModelAdapter:\n",
    "    \"\"\"灰度模型适配器\"\"\"\n",
    "    @staticmethod\n",
    "    def convert_model(model, checkpoint_path):\n",
    "        # 加载预训练权重\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # 调整第一层卷积\n",
    "        original_conv = model.features[0][0]\n",
    "        new_conv = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=original_conv.out_channels,\n",
    "            kernel_size=original_conv.kernel_size,\n",
    "            stride=original_conv.stride,\n",
    "            padding=original_conv.padding,\n",
    "            bias=original_conv.bias is not None\n",
    "        )\n",
    "        \n",
    "        # 权重转换策略\n",
    "        with torch.no_grad():\n",
    "            if original_conv.weight.shape[1] == 3:\n",
    "                # RGB转灰度：使用加权平均\n",
    "                weights = original_conv.weight.data\n",
    "                gray_weights = (0.2989 * weights[:,0] + 0.5870 * weights[:,1] + 0.1140 * weights[:,2]).unsqueeze(1)\n",
    "                new_conv.weight.data = gray_weights\n",
    "            else:\n",
    "                new_conv.weight.data = original_conv.weight.data.mean(dim=1, keepdim=True)\n",
    "            \n",
    "            if new_conv.bias is not None:\n",
    "                new_conv.bias.data = original_conv.bias.data.clone()\n",
    "        \n",
    "        model.features[0][0] = new_conv\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def freeze_layers(model):\n",
    "        # 冻结指定层\n",
    "        for name, param in model.named_parameters():\n",
    "            if not any([layer in name for layer in GrayConfig.config['unfreeze_layers']]):\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "        return model\n",
    "\n",
    "# ----------------------\n",
    "# 6. 训练流程优化\n",
    "# ----------------------\n",
    "def train_gray():\n",
    "    # 初始化配置\n",
    "    seed_everything(42)\n",
    "    cfg = GrayConfig.config\n",
    "    os.makedirs(cfg['model_dir'], exist_ok=True)\n",
    "\n",
    "    # 数据加载\n",
    "    transforms = get_gray_transforms()\n",
    "    full_dataset = GrayDataset(cfg['data_dir'], transform=transforms['train'])\n",
    "    train_size = int((1 - cfg['valid_ratio']) * len(full_dataset))\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(full_dataset, [train_size, len(full_dataset)-train_size])\n",
    "    valid_dataset.dataset.transform = transforms['valid']\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=cfg['num_workers'],\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True if cfg['num_workers']>0 else False\n",
    "    )\n",
    "\n",
    "    # 模型初始化\n",
    "    model = models.efficientnet_b0()\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(model.classifier[1].in_features, cfg['num_classes'])\n",
    "    )\n",
    "    model = GrayModelAdapter.convert_model(model, cfg['pretrained'])\n",
    "    model = GrayModelAdapter.freeze_layers(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 优化器配置\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=cfg['learning_rate'],\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=len(train_loader)*2,\n",
    "        T_mult=1,\n",
    "        eta_min=1e-7\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=cfg['label_smoothing'])\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # 早停机制\n",
    "    best_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    # 记录训练历史\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'valid_loss': [],\n",
    "        'valid_acc': []\n",
    "    }\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(cfg['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{cfg['num_epochs']}\")\n",
    "        \n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        progress_bar = tqdm(train_loader, desc='Training', dynamic_ncols=True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for step, (inputs, labels) in enumerate(progress_bar):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            # 混合精度训练\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss = loss / cfg['grad_accum_steps']\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # 累积训练统计\n",
    "            train_loss += loss.item() * cfg['grad_accum_steps']\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            train_acc = 100. * correct / total\n",
    "\n",
    "            # 梯度累积\n",
    "            if (step+1) % cfg['grad_accum_steps'] == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "\n",
    "            # 更新进度条\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item()*cfg['grad_accum_steps']:.3f}\",\n",
    "                'acc': f\"{train_acc:.1f}%\",\n",
    "                'lr': f\"{optimizer.param_groups[0]['lr']:.1e}\",\n",
    "                'mem': f\"{torch.cuda.memory_reserved(device)/1e9:.1f}G\" if torch.cuda.is_available() else \"N/A\"\n",
    "            })\n",
    "\n",
    "        # 计算平均训练损失\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # 验证阶段\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=cfg['batch_size']*2,\n",
    "            shuffle=False,\n",
    "            num_workers=cfg['num_workers']\n",
    "        )\n",
    "        valid_loss, valid_acc = validate(model, valid_loader, criterion)\n",
    "        \n",
    "        # 记录历史\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['valid_loss'].append(valid_loss)\n",
    "        history['valid_acc'].append(valid_acc)\n",
    "        \n",
    "        # 打印验证结果\n",
    "        print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.1f}%\")\n",
    "\n",
    "        # 模型保存逻辑\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            epochs_no_improve = 0\n",
    "            save_path = os.path.join(cfg['model_dir'], f'gray_best_acc{best_acc:.1f}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_acc': best_acc,\n",
    "            }, save_path)\n",
    "            print(f\"New best model saved with acc {best_acc:.1f}%\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= cfg['es_patience']:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "\n",
    "        # 释放内存\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"Training completed. Best validation accuracy: {best_acc:.1f}%\")\n",
    "    \n",
    "    # 绘制训练曲线\n",
    "    plot_training_history(history, cfg['model_dir'])\n",
    "\n",
    "def plot_training_history(history, save_dir):\n",
    "    \"\"\"绘制训练历史\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    # 损失曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['valid_loss'], label='Valid')\n",
    "    plt.title('Training/Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 准确率曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train')\n",
    "    plt.plot(history['valid_acc'], label='Valid')\n",
    "    plt.title('Training/Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 保存图像\n",
    "    save_path = os.path.join(save_dir, 'gray_training_metrics.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved training metrics plot to: {save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models, transforms\n",
    "from torch.amp import GradScaler, autocast\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------------------\n",
    "# 1. 系统配置\n",
    "# ----------------------\n",
    "class TrainingConfig:\n",
    "    # 自动模型选择\n",
    "    @staticmethod\n",
    "    def select_model(model_dir=\"visionModel\"):\n",
    "        models = glob.glob(os.path.join(model_dir, \"*.pth\"))\n",
    "        if not models:\n",
    "            return None\n",
    "        \n",
    "        print(\"\\n发现预训练模型:\")\n",
    "        for i, path in enumerate(models, 1):\n",
    "            acc = re.search(r\"acc([\\d.]+)\", path)\n",
    "            acc = acc.group(1) if acc else \"未知\"\n",
    "            print(f\"[{i}] {os.path.basename(path)} (准确率: {acc}%)\")\n",
    "        \n",
    "        print(\"[0] 从头开始训练\")\n",
    "        choice = int(input(\"请选择模型编号: \"))\n",
    "        return models[choice-1] if choice > 0 else None\n",
    "\n",
    "    # 训练参数\n",
    "    config = {\n",
    "        \"data_dir\": \"archive/data_relabeled_balanced_1x/train\",\n",
    "        \"model_dir\": \"visionModel_enhanced\",\n",
    "        \"batch_size\": 128,\n",
    "        \"grad_accum_steps\": 2,\n",
    "        \"num_epochs\": 100,\n",
    "        \"learning_rate\": 3e-5,\n",
    "        \"num_classes\": 8,\n",
    "        \"input_size\": 224,\n",
    "        \"valid_ratio\": 0.15,\n",
    "        \"num_workers\": 4 if os.cpu_count() > 4 else 0,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"freeze_blocks\": 2,\n",
    "        \"es_patience\": 8\n",
    "    }\n",
    "\n",
    "# ----------------------\n",
    "# 2. 混合数据集\n",
    "# ----------------------\n",
    "class HybridDataset(Dataset):\n",
    "    \"\"\"支持彩色和灰度混合训练的数据集\"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = self._get_classes()\n",
    "        self.class_to_idx = {cls:i for i, cls in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 加载所有图像路径（包含彩色和灰度）\n",
    "        for cls in self.classes:\n",
    "            # 彩色目录\n",
    "            color_dir = os.path.join(root_dir, cls)\n",
    "            if os.path.exists(color_dir):\n",
    "                self.samples += [\n",
    "                    (os.path.join(color_dir, f), self.class_to_idx[cls])\n",
    "                    for f in os.listdir(color_dir) \n",
    "                    if f.lower().endswith(('png','jpg','jpeg'))\n",
    "                ]\n",
    "\n",
    "            # 灰度目录\n",
    "            gray_dir = os.path.join(root_dir, f\"{cls}_gray\")\n",
    "            if os.path.exists(gray_dir):\n",
    "                self.samples += [\n",
    "                    (os.path.join(gray_dir, f), self.class_to_idx[cls])\n",
    "                    for f in os.listdir(gray_dir)\n",
    "                    if f.lower().endswith(('png','jpg','jpeg'))\n",
    "                ]\n",
    "\n",
    "    def _get_classes(self):\n",
    "        \"\"\"获取有效类别列表（过滤灰度目录）\"\"\"\n",
    "        all_dirs = [d for d in os.listdir(self.root_dir) \n",
    "                   if os.path.isdir(os.path.join(self.root_dir, d))]\n",
    "        return sorted({d.replace('_gray', '') for d in all_dirs})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert('RGB')  # 统一转为三通道\n",
    "        \n",
    "        if self.transform:\n",
    "            img = np.array(img)\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "# ----------------------\n",
    "# 3. 数据增强\n",
    "# ----------------------\n",
    "def get_transforms():\n",
    "    return {\n",
    "        'train': A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.OneOf([\n",
    "                A.RandomGamma(gamma_limit=(80, 120)),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "            ], p=0.5),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.1, \n",
    "                scale_limit=0.2, \n",
    "                rotate_limit=20,\n",
    "                border_mode=cv2.BORDER_REFLECT_101,\n",
    "                p=0.5\n",
    "            ),\n",
    "            A.CoarseDropout(\n",
    "                max_holes=5,\n",
    "                max_height=0.2, \n",
    "                max_width=0.2,\n",
    "                p=0.3\n",
    "            ),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        'valid': A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    }\n",
    "\n",
    "# ----------------------\n",
    "# 4. 模型工具\n",
    "# ----------------------\n",
    "def create_model(num_classes, pretrained=None):\n",
    "    \"\"\"创建/加载模型\"\"\"\n",
    "    model = models.efficientnet_b0(pretrained=False)\n",
    "    \n",
    "    # 修改分类层\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    # 加载预训练权重\n",
    "    if pretrained:\n",
    "        print(f\"加载预训练模型: {pretrained}\")\n",
    "        checkpoint = torch.load(pretrained)\n",
    "        \n",
    "        # 自适应调整第一层卷积\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "        current_conv = model.features[0][0]\n",
    "        \n",
    "        # 处理输入通道不匹配的情况\n",
    "        if state_dict['features.0.0.weight'].shape[1] != current_conv.in_channels:\n",
    "            print(\"调整输入通道...\")\n",
    "            orig_weight = state_dict['features.0.0.weight']\n",
    "            if current_conv.in_channels == 3:\n",
    "                # 灰度转彩色：复制单通道权重到三通道\n",
    "                new_weight = orig_weight.repeat(1,3,1,1) / 3.0\n",
    "            else:\n",
    "                # 彩色转灰度：取三通道均值\n",
    "                new_weight = orig_weight.mean(dim=1, keepdim=True)\n",
    "            \n",
    "            state_dict['features.0.0.weight'] = new_weight\n",
    "        \n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    # 冻结部分层\n",
    "    for param in model.features[:TrainingConfig.config['freeze_blocks']].parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    return model.to(device)\n",
    "\n",
    "# ----------------------\n",
    "# 5. 训练引擎\n",
    "# ----------------------\n",
    "def train():\n",
    "    # 初始化配置\n",
    "    config = TrainingConfig.config\n",
    "    os.makedirs(config['model_dir'], exist_ok=True)\n",
    "    \n",
    "    # 选择设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"使用设备: {device}\")\n",
    "    \n",
    "    # 数据加载\n",
    "    transforms = get_transforms()\n",
    "    dataset = HybridDataset(config['data_dir'], transform=transforms['train'])\n",
    "    train_size = int((1 - config['valid_ratio']) * len(dataset))\n",
    "    train_set, valid_set = random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "    valid_set.dataset.transform = transforms['valid']\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # 模型初始化\n",
    "    pretrained = TrainingConfig.select_model()\n",
    "    model = create_model(config['num_classes'], pretrained)\n",
    "    \n",
    "    # 优化器配置\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    \n",
    "    # 加载优化器状态（如果存在）\n",
    "    if pretrained:\n",
    "        checkpoint = torch.load(pretrained)\n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            print(\"已加载优化器状态\")\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max', \n",
    "        factor=0.5, \n",
    "        patience=3,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # 训练循环\n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'valid_loss': [], 'valid_acc': []}\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n",
    "        \n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc='Training')\n",
    "        for step, (inputs, labels) in enumerate(progress_bar):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (step+1) % config['grad_accum_steps'] == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # 统计指标\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            acc = 100. * correct / total\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item():.3f}\",\n",
    "                'acc': f\"{acc:.1f}%\",\n",
    "                'lr': f\"{optimizer.param_groups[0]['lr']:.1e}\"\n",
    "            })\n",
    "        \n",
    "        # 验证阶段\n",
    "        valid_loss, valid_acc = validate(model, DataLoader(\n",
    "            valid_set, \n",
    "            batch_size=config['batch_size']*2,\n",
    "            shuffle=False\n",
    "        ), criterion)\n",
    "        \n",
    "        # 记录历史\n",
    "        history['train_loss'].append(total_loss/len(train_loader))\n",
    "        history['train_acc'].append(acc)\n",
    "        history['valid_loss'].append(valid_loss)\n",
    "        history['valid_acc'].append(valid_acc)\n",
    "        \n",
    "        # 学习率调整\n",
    "        scheduler.step(valid_acc)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_acc': best_acc,\n",
    "            }, os.path.join(config['model_dir'], f'enhanced_acc{best_acc:.1f}.pth'))\n",
    "            print(f\"保存最佳模型，准确率: {best_acc:.1f}%\")\n",
    "        \n",
    "        # 早停检测\n",
    "        if (epoch - np.argmax(history['valid_acc'])) >= config['es_patience']:\n",
    "            print(\"早停触发\")\n",
    "            break\n",
    "    \n",
    "    # 保存训练曲线\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['valid_loss'], label='Valid')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(history['train_acc'], label='Train')\n",
    "    plt.plot(history['valid_acc'], label='Valid')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(os.path.join(config['model_dir'], 'training_curves.png'))\n",
    "    plt.close()\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc='Validating'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return total_loss/len(loader), 100.*correct/total\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
